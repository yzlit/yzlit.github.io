[{"title":"千万流量RPC架构长啥样","date":"2019-01-19T12:52:41.000Z","path":"2019/01/19/千万流量RPC架构长啥样/","text":"先举个例子感受一下千万级到底是什么数量级？现在很流行的优步(Uber)，从媒体公布的信息看，它每天接单量平均在百万左右， 假如每天有10个小时的服务时间，平均QPS只有30左右。对于一个后台服务器，单机的平均QPS可以到达800-1000，单独看写的业务量很简单 。为什么我们又不能说轻视它？第一，我们看它的数据存储，每天一百万的话，一年数据量的规模是多少？其次，刚才说的订单量，每一个订单要推送给附近的司机、司机要并发抢单，后面业务场景的访问量往往是前者的上百倍，轻松就超过上亿级别了。 今天我想从架构的本质谈起之后，希望大家理解在做一些建构设计的时候，它的出发点以及它解决的问题是什么。 架构，刚开始的解释是我从知乎上看到的。什么是架构？有人讲， 说架构并不是一 个很 悬 乎的 东西 ， 实际 上就是一个架子 ， 放一些 业务 和算法，跟我们的生活中的晾衣架很像。更抽象一点，说架构其 实 是 对 我 们 重复性业务 的抽象和我 们 未来 业务 拓展的前瞻，强调过去的经验和你对整个行业的预见。 我们要想做一个架构的话需要哪些能力？我觉得最重要的是架构师一个最重要的能力就是你要有 战 略分解能力。这个怎么来看呢: 第一，你必须要有抽象的能力，抽象的能力最基本就是去重，去重在整个架构中体现在方方面面，从定义一个函数，到定义一个类，到提供的一个服务，以及模板，背后都是要去重提高可复用率。第二， 分类能力。做软件需要做对象的解耦，要定义对象的属性和方法，做分布式系统的时候要做服务的拆分和模块化，要定义服务的接口和规范。第三， 算法（性能），它的价值体现在提升系统的性能，所有性能的提升，最终都会落到CPU，内存，IO和网络这4大块上。 这一页PPT举了一些例子来更深入的理解常见技术背后的架构理念。 第一个例子，在分布式系统我们会做 MySQL分 库 分表，我们要从不同的库和表中读取数据，这样的抽象最直观就是使用模板，因为绝大多数SQL语义是相同的，除了路由到哪个库哪个表，如果不使用Proxy中间件，模板就是性价比最高的方法。 第二看一下加速网络的CDN，它是做速度方面的性能提升，刚才我们也提到从CPU、内存、IO、网络四个方面来考虑，CDN本质上一个是做网络智能调度优化，另一个是多级缓存优化。 第三个看一下服务化，刚才已经提到了，各个大网站转型过程中一定会做服务化，其实它就是做抽象和做服务的拆分。第四个看一下消息队列，本质上还是做分类，只不过不是两个边际清晰的类，而是把两个边际不清晰的子系统通过队列解构并且异步化。 新浪微博整体架构是什么样的 接下我们看一下微博整体架构，到一定量级的系统整个架构都会变成三层，客户端包括WEB、安卓和IOS，这里就不说了。接着还都会有一个接口层， 有三个主要作用： 第一个作用，要做 安全隔离，因为前端节点都是直接和用户交互，需要防范各种恶意攻击； 第二个还充当着一个 流量控制的作用，大家知道，在2014年春节的时候，微信红包，每分钟8亿多次的请求，其实真正到它后台的请求量，只有十万左右的数量级（这里的数据可能不准），剩余的流量在接口层就被挡住了； 第三，我们看对 PC 端和移 动 端的需求不一样的，所以我们可以进行拆分。接口层之后是后台，可以看到微博后台有三大块： 一个是 平台服 务， 第二， 搜索， 第三， 大数据。到了后台的各种服务其实都是处理的数据。 像平台的业务部门，做的就是 数据存储和读 取，对搜索来说做的是 数据的 检 索，对大数据来说是做的数据的 挖掘。微博其实和淘宝是很类似 微博其实和淘宝是很类似的。一般来说，第一代架构，基本上能支撑到用户到 百万 级别，到第二代架构基本能支撑到 千万 级别都没什么问题，当业务规模到 亿级别时，需要第三代的架构。 从 LAMP 的架构到面向服 务 的架构，有几个地方是非常难的，首先不可能在第一代基础上通过简单的修修补补满足用户量快速增长的，同时线上业务又不能停， 这是我们常说的 在 飞 机上 换 引擎的 问题。前两天我有一个朋友问我，说他在内部推行服务化的时候，把一个模块服务化做完了，其他部门就是不接。我建议在做服务化的时候，首先更多是偏向业务的梳理，同时要找准一个很好的切入点，既有架构和服务化上的提升，业务方也要有收益，比如提升性能或者降低维护成本同时升级过程要平滑，建议开始从原子化服务切入，比如基础的用户服务， 基础的短消息服务，基础的推送服务。 第二，就是可 以做无状 态 服 务，后面会详细讲，还有数据量大了后需要做数据Sharding，后面会将。 第三代 架构 要解决的 问题，就是用户量和业务趋于稳步增加（相对爆发期的指数级增长），更多考虑技术框架的稳定性， 提升系统整体的性能，降低成本，还有对整个系统监控的完善和升级。 大型网站的系统架构是如何演变的 我们通过通过数据看一下它的挑战，PV是在10亿级别，QPS在百万，数据量在千亿级别。我们可用性，就是SLA要求4个9，接口响应最多不能超过150毫秒，线上所有的故障必须得在5分钟内解决完。如果说5分钟没处理呢？那会影响你年终的绩效考核。2015年微博DAU已经过亿。我们系统有上百个微服务，每周会有两次的常规上线和不限次数的紧急上线。我们的挑战都一样，就是数据量，bigger and bigger，用户体验是faster and faster，业务是more and more。互联网业务更多是产品体验驱动， 技 术 在 产 品 体验上最有效的贡献 ， 就是你的性能 越来越好 。 每次降低加载一个页面的时间，都可以间接的降低这个页面上用户的流失率。 微博的技术挑战和正交分解法解析架构 下面看一下 第三代的 架构 图 以及 我 们 怎么用正交分解法 阐 述。 我们可以看到我们从两个维度，横轴和纵轴可以看到。 一个 维 度 是 水平的 分层 拆分，第二从垂直的维度会做拆分。水平的维度从接口层、到服务层到数据存储层。垂直怎么拆分，会用业务架构、技术架构、监控平台、服务治理等等来处理。我相信到第二代的时候很多架构已经有了业务架构和技术架构的拆分。我们看一下， 接口层有feed、用户关系、通讯接口；服务层，SOA里有基层服务、原子服务和组合服务，在微博我们只有原子服务和组合服务。原子服务不依赖于任何其他服务，组合服务由几个原子服务和自己的业务逻辑构建而成 ，资源层负责海量数据的存储（后面例子会详细讲）。技 术框架解决 独立于 业务 的海量高并发场景下的技术难题，由众多的技术组件共同构建而成 。在接口层，微博使用JERSY框架，帮助你做参数的解析，参数的验证，序列化和反序列化；资源层，主要是缓存、DB相关的各类组件，比如Cache组件和对象库组件。监 控平台和服 务 治理 ， 完成系统服务的像素级监控，对分布式系统做提前诊断、预警以及治理。包含了SLA规则的制定、服务监控、服务调用链监控、流量监控、错误异常监控、线上灰度发布上线系统、线上扩容缩容调度系统等。","tags":[{"name":"RPC 高并发","slug":"RPC-高并发","permalink":"http://yzlit.gitee.io/tags/RPC-高并发/"}]},{"title":"Java后台开发的修仙之路","date":"2019-01-13T15:59:37.000Z","path":"2019/01/13/后台开发的修仙之路/","text":"一、基础这个阶段无他，多尝试，多学习，熟悉各种基础，对技术广度要有一定追求。 1，语言基础 Java （以及其他语言Python，Go和一些前端涉略html Javascript）语法及语言特性 代码量要不断累积，主要是为了熟悉。 2，数据结构 数组，链表，树，图， 以及排序算法 3，linux命令 4，数据库 基础理论，sql语句，各种常用的数据库mysql mongodb redis memcache 5，计算机网络 TCP UDP OSI MTU等等基础 6，设计模式 工厂，原型，生成器，等等 7，项目经验 主要对一些SSM，netty等等框架的应用到个人项目中，有一定的实战经验。 二、进阶这个阶段是脱离基础阶段只会用的程度，上升到知道为什么，以及具有活用到实际开发的能力，还要多多阅读源码，深入底层。 1，jvm虚拟机以及语言库的实现源码和原理：常见hashmap,table，concurrrentHashmap等等基本库。 2，算法：leetcode,剑指offer （ACM看个人吧） 3，linux操作系统底层原理 4，数据库原理，调优，（mysql mongodb redis memcache ） 5，spring SpringMVC mybatis ,netty等基本框架的源码解析，注意源码的框架思路，设计模式 三、架构1，通信框架 netty websocket 2，其他中间件nginx,zookeeper,消息队列(rabbitmq，kafka,acctiveMQ)，docker。 3，数据库高可用架构 搜索数据库ES 大数据数据库Hbase 4,架构师个人非技术的修养 程序员的自我修养 代码之道 Head to Java First 等书 最后送给自己一句话：「 你会的东西，有没有价值？你有没有把写代码的严谨和真实用到为人处事上面，有没有把和自己死磕的精神用到工作里面去。如果没有，那你不要说你努力了。」","tags":[{"name":"后台开发,Java","slug":"后台开发-Java","permalink":"http://yzlit.gitee.io/tags/后台开发-Java/"}]},{"title":"Redis使用笔记","date":"2019-01-13T04:23:55.000Z","path":"2019/01/13/redis使用笔记/","text":"I Redis持久化的方式有两种：​ 1.RDB:对内存中数据库状态进行快照​ 2.AOF:把每条写命令都写入文件，类似于mysql的binlog日志​ 一、 RDB方式：将Redis在内存中的数据库状态保存到磁盘里面，RDB文件是一个经过 压缩的二进制文件，通过该文件可以还原生成RDB文件的数据状态。 RDB的生成方式： 1.指向命令手动生成​ 有两个Redis命令可以生成RDB文件，一个是SAVE，另一个是BGSAVE，SAVE 命令会阻塞Redis服务器进程，知道RDB文件创建完毕为止，在服务器阻塞期间,服 务器不能处理任何的进程,BGSAVE会派出一个子进程，然后由子进程负责创建RDB 文件，服务器进程（父进程）继续处理命令请求，创建RDB文件结束之前，客户端 发送的 BGSAVE 和 SAVE 命令会被服务器拒绝 2.通过配置自动生成​ 可以设置服务器配置的save选项，让服务器每隔一段时间自动执行一次BGSAVE命令，可以通过save选项设置多个保存条件，但只要其中任意一个条件被满足就会执行BGSAGE命令​ 列如：​ save 900 1​ save 300 10​ save 60 10000​ 那么只要满足以下三个条件中的其中一个，BGSAVE命令就会被执行​ 服务器在 900 秒之内，对数据库进行了 1 次修改​ 服务器在 300 秒之内，对数据库进行了 10 次修改​ 服务器在 900 秒之内，对数据库进行了 10000 次修改 二，AOF方式：是通过保存Redis服务器所执行的写命令来记录数据库状态的AOF文件刷新方式，有三种： 1.appendfsync always –每提交一个修改命令都调用fsync到AOF文件，非常慢，但是很安全； 2.appendfsync everysec–每秒都调用fsyns刷新到AOF文件，很快但可能丢失一秒内的数据； 3.appendfsync no–依靠OS进行刷新，redis不主动刷新AOF，这样最快但是安全性差； 默认并且推荐每秒刷新，这样在速度和安全上都做到了兼顾 配置如下 appendonly yes #启用AOF appendfilename appendonly.aof #AOF文件的名称 # appendfsync always appendfsync everysec #每秒钟强制写入磁盘一次 # appendfsync no II 数据恢复1.ROB方式​ ROB文件的载入工作是在服务器启动时自动执行的，没有专门用于载入ROB文件命令，只要Redis服务器再启动时检测到ROB文件存在，它就会自动载入ROB的文件，在服务器载入的期间，会一直处于阻塞状态，知道载入工作完成为止 2.AOF方式​ 服务器在启动时，通过载入和执行AOF文件中保存的命令来还原服务器关闭之前的数据，具体库状态过程：​ 载入AOF文件​ 创建模拟客户端​ 从AOF文件中读取一条命令​ 使用模拟客户端执行命令​ 循环读取并执行命令，知道全部完成 注意：如果同时启动了AOF和ROB方式，AOF优先，启动时只加载AOF文件恢复数时之加载","tags":[{"name":"Redis","slug":"Redis","permalink":"http://yzlit.gitee.io/tags/Redis/"}]},{"title":"数据库ACID特性和事务","date":"2019-01-13T04:23:55.000Z","path":"2019/01/13/数据库四大特性及事务/","text":"ACID特性原子性原子性是指数据库事务时不可分割的工作单位。只有使实物中所有的数据库操作都执行成功，才算整个事务成功。事务中任何一个SQL语句执行失败，已经执行成功的SQL语句也必须撤销，退回到事务前的状态。 一致性事务将数据库从一种状态转变为下一种一致的状态。在事务开始之前和事务结束之后，数据库的完整性约束没有被破坏。 隔离性每个读写事务的对象对其他事务的操作对象相互分离，即该事务提交前对其他事务都不可见，通常使用锁来实现。 持久性 事务一旦提交，其结果就是永久性的。及时发送宕机等故障，数据库也能将数据恢复。作者：YinXinLion来源：CSDN原文：https://blog.csdn.net/qq_27602093/article/details/77069765版权声明：本文为博主原创文章，转载请附上博文链接！","tags":[{"name":"跨域访问","slug":"跨域访问","permalink":"http://yzlit.gitee.io/tags/跨域访问/"}]},{"title":"跨域问题详解","date":"2019-01-13T04:23:55.000Z","path":"2019/01/13/跨域问题/","text":"一、什么是跨域？ 浏览器从一个域名的网页去请求另一个域名的资源时，域名、端口、协议任一不同，都是跨域。跨域访问会访问状态码200但是无法访问，还有其他附带的问题，请求COOKIE无法带上。 比如你从域名为120.258.45 的index.html要访问 156.85.14:8000/getaccess 接口，那么就会有跨域问题。一般尝试跨域访问就会出现No ‘Access-Control-Allow-Origin’ header is present on the requested resource.’ ，类似你可以从谷歌控制台，看到提示： 二、为什么要禁止跨域访问这要涉及到浏览器的同源策略，同源策略限制了不同源之间的资源进行交互，用于隔离潜在的恶意文件的安全机制，并且是浏览器最基本的安全机制（同源：协议、域名、端口均相同，localhost和127.0.0.1也属于跨域）。 如果非同源，同源政策限制三种行为： （1） Cookie、LocalStorage 和 IndexDB 无法读取。 （2） DOM 无法获得。 （3） AJAX 请求不能发送。 对于（1） Cookie、LocalStorage 和 IndexDB 无法读取，如果没有同源策略的限制，假设您进入一个受信网站A，输入了账号密码进行登录，服务器端验证通过后会在响应头中添加Set-Cookie字段，在下次访问时，浏览器就会将cookie附加在http请求头字段Cookie中，服务器就知道您已经登录过，下次你再带着这个cookie时访问受信网站A，服务器便不再验证了，如果在cookie信息还存在的情况下，您不小心访问另一个恶意钓鱼网站B，在您不知情的情况下向受信网站A发起了请求，这就相当于不法钓鱼网站登录了您的账户，可以为所欲为了！ 对于（2） DOM 无法获得。又比如一个钓鱼网站，模仿银行网站A（没有了同源策略的限制，钓鱼网站就可以很轻松的网站A的DOM），诱导您输入账户密码信息，你的信息就没了，所以最近12306就是因为类似第三方的访问导致410万用户密码等信息泄漏。 对于（3） AJAX 请求不能发送同源政策规定，AJAX请求只能发给同源的网址，否则就报错。 三、怎么解决跨域问题详细的同源策略通过前端解决的介绍可以看阮一峰的文章http://www.ruanyifeng.com/blog/2016/04/same-origin-policy.html 除了上述解决方法，服务端解决跨域会用到CORS，CORS是一个W3C标准，全称是”跨域资源共享“。详细的可以见阮一峰的文章http://www.ruanyifeng.com/blog/2016/04/cors.html Nginx配置实例实例一：允许example.com的应用在www.example2.com上跨域提取数据在nginx.conf里找到server项,并在里面添加如下配置 1`location /&#123;` `add_header ``&apos;Access-Control-Allow-Origin&apos;` `&apos;http://example.com&apos;``;``add_header ``&apos;Access-Control-Allow-Credentials&apos;` `&apos;true&apos;``;``add_header ``&apos;Access-Control-Allow-Headers&apos;` `&apos;Authorization,Content-Type,Accept,Origin,User-Agent,DNT,Cache-Control,X-Mx-ReqToken,X-Requested-With&apos;``;``add_header ``&apos;Access-Control-Allow-Methods&apos;` `&apos;GET,POST,OPTIONS&apos;``;``...``&#125;` 如果需要允许来自任何域的访问，可以这样配置 1`add_header Access-Control-Allow-Origin *;` 注释如下 第一条指令：授权从example.com的请求(必需) 第二条指令：当该标志为真时，响应于该请求是否可以被暴露(可选) 第三条指令：允许脚本访问的返回头(可选) 第四条指令：指定请求的方法，可以是GET, POST, OPTIONS, PUT, DELETE等(可选) 重启Nginx 1`$ service nginx reload` 测试跨域请求 1`$ curl -I -X OPTIONS -H ``&quot;Origin: http://example.com&quot;` `http:``//www``.example2.com` 成功时，响应头是如下所示 1`HTTP``/1``.1 200 OK``Server: nginx``Access-Control-Allow-Origin: example.com` 实例二：Nginx允许多个域名跨域访问由于Access-Control-Allow-Origin参数只允许配置单个域名或者 * ，当我们需要允许多个域名跨域访问时可以用以下几种方法来实现。 方法一 如需要允许用户请求来自www.example.com、m.example.com、wap.example.com访问www.example2.com域名时，返回头Access-Control-Allow-Origin，具体配置如下 在nginx.conf里面,找到server项,并在里面添加如下配置 具体其他可看：https://www.cnblogs.com/sunmmi/articles/5956554.html 1`map $http_origin $corsHost &#123;`` ``default 0;`` ``&quot;~http://www.example.com&quot;` `http:``//www``.example.com;`` ``&quot;~http://m.example.com&quot;` `http:``//m``.example.com;`` ``&quot;~http://wap.example.com&quot;` `http:``//wap``.example.com;``&#125;` `server``&#123;`` ``listen 80;`` ``server_name www.example2.com;`` ``root ``/usr/share/nginx/html``;`` ``location /`` ``&#123;`` ``add_header Access-Control-Allow-Origin $corsHost;`` ``&#125;``&#125;`","tags":[{"name":"跨域访问","slug":"跨域访问","permalink":"http://yzlit.gitee.io/tags/跨域访问/"}]},{"title":"工作之后如何处理好工作和学习的平衡","date":"2019-01-13T04:23:55.000Z","path":"2019/01/13/谈谈工作怎么提升自己的计划/","text":"一，工作首先最重要肯定是饭碗，对于大多数人来说，先维持一份薪水还过得去的工作，才能有力气去继续奔跑。 工作当然是枯燥的，CRUD的工作对于很多初级后台开发来说是常事，但是工作仍要做好，做出彩，如果你连工作最基本的都不肯做好，那么你又怎么可能去做好别的事，没有基本的工作，兴趣更是无从谈起。 要做好工作 ，做出彩，也是要下很大努力的。 第一个就是要注意改进工作方法，提高工作效率。别因为自己的做事方法而耽误自己的时间，那是最蠢的。 工作方法首先是一句话，规划好工作量和工作计划，小步快跑。 规划很重要，不然你不知不觉浪费的时间，就是在慢慢把你拉进水里。 第二句话，懂得职场的规矩，每个公司都有不同的职场氛围，没有一模一样的处事方法，但是为人却是差不多，与人相处，要有诚意，也要保持礼貌，既要尽责地完成自己的工作，在不影响自己的工作和时间情况下，尽量给予帮助。 二，学习 工作了就不学习，过几个月你已经落后你的同学了，再过个一两年，公司把你炒了，你也找不到下家了。 学习，很重要，也要有规划，不能东学一个ES，西学一个微服务，三天打鱼式地刷几道leetcode。 要有规划，首先要计划时间，下班后从几点开始到睡觉前，要干什么，要学什么，进度怎么控制，怎么把学到的东西用起来，记下来。 生活和学习应该放在一起考虑，学习生活才是一种好的状态。 不荒废时光，学一些东西不在于你学了就行，而在于它能最大化提升你的价值，把你的时间花值了。 前路漫漫，坚持，方得始终。","tags":[{"name":"工作 学习","slug":"工作-学习","permalink":"http://yzlit.gitee.io/tags/工作-学习/"}]},{"title":"mysql有关索引的一些总结","date":"2019-01-12T15:46:47.000Z","path":"2019/01/12/mysql索引的一些总结/","text":"一、四大索引 索引类型 适用范围 不适用 效率 引擎 全文索引(FULLTEXT) char,vachar,text列，用于like %word% 中文支持不是很好，中文分词插件Mysqlcft，用Apache的Lucene替代 低 MyISAM HASH = in &lt;=&gt; 范围查询，排序，组合索引，无法避免表扫描 需要遍历hash表 MEMORY B+树 普遍适用 与树结构有关 Innodb：1，primary key：主键+其他字段 2，secondary index：只保存主键指针 myISAM:叶子结点存放该数据的行指向 R树 geometry数据类型 范围查找 MyISAM、BDb、InnoDb、NDb、Archive 二、有关于B树和B+树的区别 B树中关键字集合分布在整棵树中，叶节点中不包含任何关键字信息，而B+树关键字集合分布在叶子结点中，非叶节点只是叶子结点中关键字的索引； B树中任何一个关键字只出现在一个结点中，而B+树中的关键字必须出现在叶节点中； 不同于B树只适合随机检索，B+树同时支持随机检索和顺序检索； B+树的磁盘读写代价更低。B+树的内部结点并没有指向关键字具体信息的指针，其内部结点比B树小，盘块能容纳的结点中关键字数量更多，一次性读入内存中可以查找的关键字也就越多，相对的，IO读写次数也就降低了。而IO读写次数是影响索引检索效率的最大因素。 B+树的查询效率更加稳定。B树搜索有可能会在非叶子结点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字全集内做一次二分查找。而在B+树中，顺序检索比较明显，随机检索时，任何关键字的查找都必须走一条从根节点到叶节点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。 数据库索引采用B+树的主要原因是，）B-树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。B+树的叶子节点使用指针顺序连接在一起，只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低）。 三、B+树比B树更适合做文件索引的原因（1）B+树空间利用率更高，可减少I/O次数，​ 一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗。而因为B+树的内部节点只是作为索引使用，而不像B-树那样每个节点都需要存储硬盘指针。​ 也就是说：B+树中每个非叶节点没有指向某个关键字具体信息的指针，所以每一个节点可以存放更多的关键字数量，即一次性读入内存所需要查找的关键字也就越多，减少了I/O操作。​ e.g.假设磁盘中的一个盘块容纳16bytes，而一个关键字2bytes，一个关键字具体信息指针2bytes。一棵9阶B-tree(一个结点最多8个关键字)的内 部结点需要2个盘快。而B+ 树内部结点只需要1个盘快。当需要把内部结点读入内存中的时候，B 树就比B+ 树多一次盘块查找时间(在磁盘中就 是 盘片旋转的时间)。 （2）增删文件（节点）时，效率更高，​ 因为B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。 （3）B+树的查询效率更加稳定，​ 因为B+树的每次查询过程中，都需要遍历从根节点到叶子节点的某条路径。所有关键字的查询路径长度相同，导致每一次查询的效率相当。 四、索引失效的情况1，不遵守最左原则 2， like like ‘%xx’ select * from tb1 where name like ‘%cn’; 3 使用函数select * from tb1 where reverse(name) = ‘wupeiqi’; 4,使用 or 时,or 条件中有未建立索引的列 select from tb1 where nid = 1 or email = &#39;seven@live.com‘;特别的：当or条件中有未建立索引的列才失效，以下会走索引 select from tb1 where nid = 1 or name = ‘seven’; select * from tb1 where nid = 1 or email = &#39;seven@live.com‘ and name = ‘alex’- 类型不一致5，使用 ！= &gt; 如果列是字符串类型，传入条件是必须用引号引起来 特别的：如果是主键，则还是会走索引 select from tb1 where nid != 123 - &gt; select from tb1 where name &gt; ‘alex’ 特别的：如果是主键或索引是整数类型，则还是会走索引select * from tb1 where nid &gt; 123 select * from tb1 where num &gt; 123- order by select email from tb1 order by name desc; 6 ,当根据索引排序时候，选择的映射如果不是索引，则不走索引 特别的：如果对主键排序，则还是走索引： select * from tb1 order by nid desc 五、sql代码查看MySQL慢日志 mysqldumpslow -s at -a /usr/local/`var/mysql/MacBook-Pro-3-slow.log` 全文索引 创建ALTER TABLE table ADD INDEX FULLINDEX USING FULLTEXT(cname1[,cname2…]); 使用SELECT * FROM table WHERE MATCH(cname1[,cname2…]) AGAINST (‘word’ MODE ); 创建普通索引 CREATE INDEX index_name ON table_name(col_name); 创建唯一索引 CREATE UNIQUE INDEX index_name ON table_name(col_name); 创建普通组合索引 CREATE INDEX index_name ON table_name(col_name_1,col_name_2); 创建唯一组合索引 CREATE UNIQUE INDEX index_name ON table_name(col_name_1,col_name_2); 通用 ALTER TABLE interface ADD FULLTEXT（INDEX） fullText_index(interfaceName); 直接删除索引 DROP INDEX index_name ON table_name; –修改表结构删除索引 ALTER TABLE table_name DROP INDEX index_name; 六、 sql优化 1.Innerjoin和左连接，右连接，子查询 A. inner join内连接也叫等值连接是，left/rightjoin是外连接。能用inner join连接尽量使用inner join连接 B．子查询的性能又比外连接性能慢，尽量用外连接来替换子查询。 C 使用JOIN时候，应该用小的表驱动大表，left join尽量左表小 D 尽量把牵涉到多表联合的查询拆分多个query(多个表查询效率低，容易锁表和阻塞) 详见：https://blog.csdn.net/heqinghua217/article/details/78600967 2.建立索引,加快查询性能. A，组合索引注意最左原则 B．保证连接表的索引是相同的类型，意思就是A表和B表相关联的字段，必须是同类型的。 C. 索引不会包含有NULL值的列","tags":[{"name":"索引","slug":"索引","permalink":"http://yzlit.gitee.io/tags/索引/"},{"name":"mysql","slug":"mysql","permalink":"http://yzlit.gitee.io/tags/mysql/"}]},{"title":"从服务端来讲讲限流的思路","date":"2019-01-12T15:46:47.000Z","path":"2019/01/12/从服务端来讲讲限流的思路/","text":"一 ”两窗两桶“限流算法1、固定窗口 固定窗口指的是为一定时间段的流量设置一个阈值，超过则触发限流策略（丢弃或者停留），然后直到下一个时间段重新置零开始计数， 这种策略很明显一个缺点是这个时间段的间隔要设置得好，否则会存在一个问题，就是无法“削峰填谷”，当时间间隔设为10秒100个请求量时，本来是应该正常每秒10个请求，但是突然第一秒就来了100个请求，在第一秒就变成100个请求每秒了，所以是没法达到限流缓冲的效果，所以这种策略比较粗暴简单。 「滑动窗口」可以改善上面的问题。 2、滑动窗口滑动窗口算法 类似于我们学过TCP的滑动窗口，对固定窗口的一种优化。 滑动窗口就是对固定窗口做了进一步的细分，将原先的粒度切的更细，比如1分钟的固定窗口切分为60个1秒的滑动窗口。然后统计的时间范围随着时间的推移同步后移。 虽然说滑动窗口可以改善这个问题，但是本质上还是预先划定时间片的方式，属于一种“预测”，意味着几乎肯定无法做到100%的物尽其用。 问题在在于由于访问量的不可预见性，会发生单位时间的前半段大量请求涌入，而后半段则拒绝所有请求的情况。（通常，需要可以将单位时间切的足够的小来缓解 ）其次，我们很难确定这个阈值设置在多少比较合适，只能通过经验或者模拟（如压测）来进行估计，即使是压测也很难估计的准确。集群部署中每台机器的硬件参数不同，可能导致我们需要对每台机器的阈值设置的都不尽相同。同一台机子在不同的时间点的系统压力也不一样（比如晚上还有一些任务，或其他的一些业务操作的影响），能够承受的最大阈值也不尽相同，我们无法考虑的周全。 所以滑窗模式通常适用于对某一资源的保护的需求上（或者说是承诺比较合适：我对某一接口的提供者承诺过，最高调用量不超过XX），如对db的保护，对某一服务的调用的控制上。 3，漏桶算法4，令牌桶算法二、做「限流」的最佳实践1、四种策略该如何选择？首先，固定窗口。一般来说，如非时间紧迫，不建议选择这个方案，太过生硬。但是，为了能快速止损眼前的问题可以作为临时应急的方案。 其次，滑动窗口。这个方案适用于对异常结果「高容忍」的场景，毕竟相比“两窗”少了一个缓冲区。但是，胜在实现简单。 然后，漏桶。个人觉得这个方案最适合作为一个通用方案。虽说资源的利用率上不是极致，但是「宽进严出」的思路在保护系统的同时还留有一些余地，使得它的适用场景更广。 最后，令牌桶。当你需要尽可能的压榨程序的性能（此时桶的最大容量必然会大于等于程序的最大并发能力），并且所处的场景流量进入波动不是很大（不至于一瞬间取完令牌，压垮后端系统）。 三、如何做分布式限流如果要分布式限流，那么单机限流的策略其实只需要移植一下，用新的工具如redis+lua 或者nginx+lua 又或者用zookeeper也是可以实现的，下面先具体讲讲redis+lua的分布式限流的思路和代码例子，其他有空再补上。 redis做限流的思路是先设置一个key=service1的记录，值为流量，和时间戳。这些用lua来主要是因为redis不支持事务，而lua脚本是作为一个原子操作一起执行的，lua脚本也是会存在reids内存中作为经常执行的命令串。 下面是固定窗口算法的lua脚本 1234567891011local key = KEYS[1] local limit = tonumber(KEYS[2]) ## 限流local current = tonumber(redis.call(&apos;get&apos;, key) or 0)if current + 1 &gt; limit then return 0else redis.call(&quot;INCRBY&quot;, key,&quot;1&quot;) ## 对key 加1操作 redis.call(&quot;EXPIRE&quot;, key,&quot;10&quot;) ## 过期时间设为10秒 return 1end 下面是令牌桶算法的lua脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172--- 获取令牌--- 返回码--- 0 没有令牌桶配置--- -1 表示取令牌失败，也就是桶里没有令牌--- 1 表示取令牌成功--- @param key 令牌（资源）的唯一标识--- @param permits 请求令牌数量--- @param curr_mill_second 当前毫秒数--- @param context 使用令牌的应用标识local function acquire(key, permits, curr_mill_second, context)--- 设置令牌桶的容量为5-- redis.pcall(\"HSET\", key, \"max_permits\", \"5\") ---桶令牌容量为5-- redis.pcall(\"HSET\", key, \"apps\", context) ---设置要取的key为apps-- redis.pcall(\"HSET\", key, \"rate\", \"0.2\") ---设置令牌桶每0.2秒增加一个令牌-- redis.pcall(\"HSET\", key, \"curr_permits\", \"0\") ---初始化零时刻时令牌桶的令牌数为0-- 这里可以交由可交由另外的脚本执行。local rate_limit_info = redis.pcall(\"HMGET\", key, \"last_mill_second\", \"curr_permits\", \"max_permits\", \"rate\", \"apps\")local last_mill_second = rate_limit_info[1]local curr_permits = tonumber(rate_limit_info[2])local max_permits = tonumber(rate_limit_info[3])local rate = rate_limit_info[4]local apps = rate_limit_info[5]--- 如果没有初始化redis里的令牌桶信息，需要首次初始化令牌桶的一些信息--if not apps or string.find(apps, context, 1)~=nil then----- if type(apps) == 'boolean' or apps == nil then--redis.pcall(\"HSET\", key, \"apps\", context)--apps=context--end--if not rate then--redis.pcall(\"HSET\", key, \"rate\", \"0.2\")--rate=0.2--end--if not curr_permits then--redis.pcall(\"HSET\", key, \"curr_permits\", \"0\")--end---初始化令牌桶完毕local local_curr_permits = max_permits;--- 令牌桶刚刚创建，上一次获取令牌的毫秒数为空--- 根据和上一次向桶里添加令牌的时间和当前时间差，触发式往桶里添加令牌--- 并且更新上一次向桶里添加令牌的时间--- 如果向桶里添加的令牌数不足一个，则不更新上一次向桶里添加令牌的时间--- if (type(last_mill_second) ~= 'boolean' and last_mill_second ~= false and last_mill_second ~= nil) then--- 桶有初始化 ，其实可以不用判断if last_mill_second thenlocal reverse_permits = math.floor(((curr_mill_second - last_mill_second) / 1000) * rate)local expect_curr_permits = reverse_permits + curr_permits;local_curr_permits = math.min(expect_curr_permits, max_permits); --- 这是此时此刻的桶令牌的数量--- 大于0表示令牌桶的数量不需要放入，因此时间戳也暂时不更新，等下一次令牌桶有增加时再更新if (reverse_permits &gt; 0) thenredis.pcall(\"HSET\", key, \"last_mill_second\", curr_mill_second) --- 更新时间戳endelseredis.pcall(\"HSET\", key, \"last_mill_second\", curr_mill_second) --- 这是初始化后的步骤 启用令牌桶，设置时间戳endlocal result = -1if (local_curr_permits - permits &gt;= 0) thenresult = 1redis.pcall(\"HSET\", key, \"curr_permits\", local_curr_permits - permits) --- 更新桶令牌的数量为拿走后剩下的数量--else--redis.pcall(\"HSET\", key, \"curr_permits\", local_curr_permits) --- 不需要更新桶令牌的数量endreturn resultendreturn acquire(KEYS[1],tonumber(KEYS[2]),tonumber(KEYS[3]),KEYS[4])","tags":[{"name":"限流","slug":"限流","permalink":"http://yzlit.gitee.io/tags/限流/"},{"name":"固定窗口","slug":"固定窗口","permalink":"http://yzlit.gitee.io/tags/固定窗口/"},{"name":"滑动窗口","slug":"滑动窗口","permalink":"http://yzlit.gitee.io/tags/滑动窗口/"},{"name":"漏桶","slug":"漏桶","permalink":"http://yzlit.gitee.io/tags/漏桶/"},{"name":"令牌桶","slug":"令牌桶","permalink":"http://yzlit.gitee.io/tags/令牌桶/"}]}]